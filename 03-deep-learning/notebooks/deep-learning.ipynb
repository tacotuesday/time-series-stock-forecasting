{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = [10, 6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "merged_df = (\n",
    "    pd.read_csv(\n",
    "        \"../data/merged_df.csv\", parse_dates=[\"timestamp\"], index_col=\"timestamp\"\n",
    "    )\n",
    "    .sort_index()\n",
    "    .convert_dtypes()\n",
    ")\n",
    "arima_predictions_T = (pd.read_csv('../data/arima_predictions_T.csv', parse_dates=['timestamp'], index_col='timestamp')\n",
    "                       .sort_index()\n",
    "                       .convert_dtypes())\n",
    "arima_predictions_V = (pd.read_csv('../data/arima_predictions_VZ.csv', parse_dates=['timestamp'], index_col='timestamp')\n",
    "                       .sort_index()\n",
    "                       .convert_dtypes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>close_t</th>\n",
       "      <th>close_v</th>\n",
       "      <th>t_diff</th>\n",
       "      <th>v_diff</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-01-02</th>\n",
       "      <td>29.54</td>\n",
       "      <td>56.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-03</th>\n",
       "      <td>29.58</td>\n",
       "      <td>56.22</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-04</th>\n",
       "      <td>30.34</td>\n",
       "      <td>56.36</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-05</th>\n",
       "      <td>30.34</td>\n",
       "      <td>56.36</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-06</th>\n",
       "      <td>30.34</td>\n",
       "      <td>56.36</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-07</th>\n",
       "      <td>30.89</td>\n",
       "      <td>56.72</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-08</th>\n",
       "      <td>31.28</td>\n",
       "      <td>58.38</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-09</th>\n",
       "      <td>30.1</td>\n",
       "      <td>57.05</td>\n",
       "      <td>-1.18</td>\n",
       "      <td>-1.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-10</th>\n",
       "      <td>30.4</td>\n",
       "      <td>57.6</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-11</th>\n",
       "      <td>30.87</td>\n",
       "      <td>58.02</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.42</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            close_t  close_v  t_diff  v_diff\n",
       "timestamp                                   \n",
       "2019-01-02    29.54    56.02     0.0     0.0\n",
       "2019-01-03    29.58    56.22    0.04     0.2\n",
       "2019-01-04    30.34    56.36    0.76    0.14\n",
       "2019-01-05    30.34    56.36     0.0     0.0\n",
       "2019-01-06    30.34    56.36     0.0     0.0\n",
       "2019-01-07    30.89    56.72    0.55    0.36\n",
       "2019-01-08    31.28    58.38    0.39    1.66\n",
       "2019-01-09     30.1    57.05   -1.18   -1.33\n",
       "2019-01-10     30.4     57.6     0.3    0.55\n",
       "2019-01-11    30.87    58.02    0.47    0.42"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before running the RNN and LSTM models, you need to create independent (X) and dependent variables (Y). You can use 10-step lag to create a dependent variable. Alternatively, you can identify your step size. Then, in order to feed the RNN model, you need to create three-dimensional data. These dimensions are samples, time steps, and features. The number of features is 1, as your model is univariate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create separate datasets out of the time series.\n",
    "t_dataset = merged_df['close_t']\n",
    "v_dataset = merged_df['close_v']\n",
    "\n",
    "# Make sure we can use the same split point for both datasets\n",
    "assert len(t_dataset) == len(v_dataset)\n",
    "\n",
    "# Creating split points to maintain temporal integrity\n",
    "split_point = int(len(t_dataset) * 0.95)\n",
    "\n",
    "t_nn_train = t_dataset.iloc[:split_point]\n",
    "t_nn_test = t_dataset.iloc[split_point:]\n",
    "v_nn_train = v_dataset.iloc[:split_point]\n",
    "v_nn_test = v_dataset.iloc[split_point:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to split the dataset into sub-sequences\n",
    "def create_dataset(data: pd.Series, window_size: int) -> tuple:\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - window_size):\n",
    "        X.append(data[i:(i + window_size)])\n",
    "        y.append(data[i + window_size])\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset\n",
    "n_steps = 10\n",
    "n_features = 1\n",
    "\n",
    "t_X_train, t_y_train = create_dataset(t_nn_train.values, n_steps)\n",
    "t_X_train = t_X_train.reshape(t_X_train.shape[0], t_X_train.shape[1], n_features)\n",
    "\n",
    "t_X_test, t_y_test = create_dataset(t_nn_test.values, n_steps)\n",
    "t_X_test = t_X_test.reshape(t_X_test.shape[0], t_X_test.shape[1], n_features)\n",
    "\n",
    "v_X_train, v_y_train = create_dataset(t_nn_train.values, n_steps)\n",
    "v_X_train = v_X_train.reshape(v_X_train.shape[0], v_X_train.shape[1], n_features)\n",
    "\n",
    "v_X_test, v_y_test = create_dataset(v_nn_test.values, n_steps)\n",
    "v_X_test = v_X_test.reshape(v_X_test.shape[0], v_X_test.shape[1], n_features)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "timeseries",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
